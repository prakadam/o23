# ============================================================================
# SEGMENT DEFINITIONS
# ============================================================================

segments = {
    'MA': page_clickstream_data[COL_MA_VISITOR] == 1,
    'MS': page_clickstream_data[COL_MS_VISITOR] == 1,
    'SNP': page_clickstream_data[COL_SNP_VISITOR] == 1,
    'MA_AEP': (page_clickstream_data[COL_MA_VISITOR] == 1) & (page_clickstream_data[COL_DURING_AEP] == 1),
}

# Segment-specific targets: browsed that plan AND completed that plan's OLE
page_clickstream_data['target_MA']  = ((page_clickstream_data['MA_Ole'] == 1) & (page_clickstream_data[COL_OLE_COMP_CT] >= 1)).astype(int)
page_clickstream_data['target_MS']  = ((page_clickstream_data['MS_Ole'] == 1) & (page_clickstream_data[COL_OLE_COMP_CT] >= 1)).astype(int)
page_clickstream_data['target_SNP'] = ((page_clickstream_data['SNP_Ole'] == 1) & (page_clickstream_data[COL_OLE_COMP_CT] >= 1)).astype(int)

segment_targets = {
    'MA':     'target_MA',
    'MS':     'target_MS',
    'SNP':    'target_SNP',
    'MA_AEP': 'target_MA',  # same target as MA, just filtered to AEP period
}

print("="*60)
print("SEGMENT SIZES")
print("="*60)
print(f"{'Segment':<15} | {'Total':>8} | {'Completed':>9} | {'Not Comp':>9} | {'Rate':>6}")
print("-"*60)
for seg_name, seg_mask in segments.items():
    seg_df = page_clickstream_data[seg_mask]
    target_col = segment_targets[seg_name]
    n_total = len(seg_df)
    n_comp = seg_df[target_col].sum()
    n_nc = n_total - n_comp
    rate = n_comp / n_total * 100 if n_total > 0 else 0
    print(f"{seg_name:<15} | {n_total:>8,} | {n_comp:>9,} | {n_nc:>9,} | {rate:>5.1f}%")

# COMMAND ----------

# ============================================================================
# HELPER: TRAIN, EVALUATE, SHAP FOR A SEGMENT
# ============================================================================

def run_segment_model(data, features, target_col, seg_name, data_dir, model_name):
    """
    Train XGBoost, evaluate, compute SHAP for a single segment.
    
    - Train on 80%, evaluate on 20% (honest AUC/precision/recall)
    - SHAP on 100% (richer feature insights)
    """
    X_all = data[features]
    y_all = data[target_col]
    
    # --- Train/Test Split ---
    X_train, X_test, y_train, y_test = train_test_split(
        X_all, y_all, test_size=0.2, random_state=42, stratify=y_all
    )
    
    print(f"\n{'='*60}")
    print(f"SEGMENT: {seg_name} — Completed vs Not")
    print(f"{'='*60}")
    print(f"  Total: {len(X_all):,}")
    print(f"  Train: {len(X_train):,} ({y_train.mean()*100:.1f}% positive)")
    print(f"  Test:  {len(X_test):,} ({y_test.mean()*100:.1f}% positive)")
    
    # --- Train ---
    neg_count = (y_train == 0).sum()
    pos_count = (y_train == 1).sum()
    
    mdl = xgb.XGBClassifier(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        scale_pos_weight=neg_count / pos_count,
        eval_metric='auc',
        random_state=42,
        use_label_encoder=False,
    )
    mdl.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=50)
    
    # --- Evaluate on TEST only (honest metrics) ---
    y_pred = mdl.predict(X_test)
    y_prob = mdl.predict_proba(X_test)[:, 1]
    
    auc = roc_auc_score(y_test, y_prob)
    print(f"\nAUC-ROC (test only): {auc:.4f}")
    print(f"\nClassification Report (test only):")
    print(classification_report(y_test, y_pred, target_names=['Not Completed', 'Completed']))
    cm = confusion_matrix(y_test, y_pred)
    print(f"Confusion Matrix (test only):")
    print(f"  TN={cm[0,0]:,}  FP={cm[0,1]:,}")
    print(f"  FN={cm[1,0]:,}  TP={cm[1,1]:,}")
    
    # --- SHAP on FULL data (all users in segment) ---
    print(f"\nComputing SHAP on full {seg_name} data ({len(X_all):,} users)...")
    explainer = shap.TreeExplainer(mdl)
    shap_vals = explainer.shap_values(X_all)
    
    # Beeswarm
    shap.summary_plot(shap_vals, X_all, max_display=25, show=False, plot_size=(12, 9))
    plt.title(f"{seg_name}: Completed vs Not — SHAP Feature Importance\n"
              f"(SHAP on {len(X_all):,} users | AUC={auc:.4f} on test)",
              fontsize=13, fontweight='bold', pad=15)
    plt.tight_layout()
    plt.savefig(f'{data_dir}{seg_name}_shap_beeswarm_{model_name}.png', dpi=200, bbox_inches='tight')
    plt.show()
    
    # Bar plot
    shap.summary_plot(shap_vals, X_all, plot_type='bar', max_display=25, show=False, plot_size=(12, 9))
    plt.title(f"{seg_name}: Mean |SHAP| — Feature Importance\n"
              f"(SHAP on {len(X_all):,} users)",
              fontsize=13, fontweight='bold', pad=15)
    plt.tight_layout()
    plt.savefig(f'{data_dir}{seg_name}_shap_bar_{model_name}.png', dpi=200, bbox_inches='tight')
    plt.show()
    
    # Feature importance table
    mean_shap = np.abs(shap_vals).mean(axis=0)
    fi = pd.DataFrame({
        'feature': features,
        'mean_abs_shap': mean_shap
    }).sort_values('mean_abs_shap', ascending=False)
    
    print(f"\n{seg_name} — Top 30 Features by Mean |SHAP|:")
    print(f"{'Rank':>4} | {'Feature':<45} | {'Mean |SHAP|':>12}")
    print("-"*70)
    for i, (_, row) in enumerate(fi.head(30).iterrows()):
        print(f"{i+1:>4} | {row['feature']:<45} | {row['mean_abs_shap']:>12.4f}")
    
    fi.to_csv(f'{data_dir}{seg_name}_feature_importance_{model_name}.csv', index=False)
    print(f"\n✓ Saved {seg_name} feature importance CSV")
    
    return mdl, shap_vals, X_all, y_all, fi, auc

# COMMAND ----------

# ============================================================================
# RUN ALL SEGMENTS
# ============================================================================

segment_results = {}

for seg_name, seg_mask in segments.items():
    seg_data = page_clickstream_data[seg_mask].copy()
    target_col = segment_targets[seg_name]
    
    # Skip if too few completers
    n_comp = seg_data[target_col].sum()
    if n_comp < 50:
        print(f"\n⚠ Skipping {seg_name} — only {n_comp} completers (need 50+)")
        continue
    
    mdl, sv, xt, yt, fi, auc = run_segment_model(
        data=seg_data,
        features=ALL_FEATURES,
        target_col=target_col,
        seg_name=seg_name,
        data_dir=DATA_DIR,
        model_name=MODEL_NAME,
    )
    
    segment_results[seg_name] = {
        'model': mdl,
        'shap_values': sv,
        'X_test': xt,
        'y_test': yt,
        'feature_importance': fi,
        'auc': auc,
    }
